# ARS: Adaptive Reflection Scheduling

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Adaptive Reflection Scheduling (ARS) is a framework for efficient language model reasoning that dynamically adjusts computational depth based on question difficulty.

## Features

-  **Adaptive Scheduling**: Automatically selects reasoning strategy based on difficulty
-  **Multiple Policies**: Vanilla, TALE, CGRS, and ARS scheduling
-  **Comprehensive Evaluation**: Support for MATH500, GSM8K, and ARC datasets
-  **Efficient**: Optimizes token usage while maintaining accuracy
-  **Benchmarking**: Built-in harness for systematic evaluation

## Installation

```bash
# Clone the repository
git clone https://github.com/dzhengAP/ars.git
cd ars

# Install dependencies
pip install -r requirements.txt
```

## Quick Start

### Test Mode

Validate your setup before running experiments:

```bash
python -m ars.main --test
```

### Single Run

Run a single experiment:

```bash
python -m ars.main \
    --model qwen-1_5b \
    --dataset gsm8k \
    --policy ars \
    --max_n 100
```

### Benchmark Mode

Run comprehensive benchmarks:

```bash
python -m ars.main --benchmark \
    --models qwen-1_5b \
    --datasets gsm8k arc \
    --policies vanilla tale cgrs ars \
    --max_n 200
```

## Project Structure

```
ars/
â”œâ”€â”€ __init__.py           # Package initialization
â”œâ”€â”€ config.py             # Configuration and constants
â”œâ”€â”€ main.py               # CLI entry point
â”œâ”€â”€ utils.py              # Utility functions
â”œâ”€â”€ answer_processing.py  # Answer extraction and normalization
â”œâ”€â”€ policies.py           # Reasoning policies
â”œâ”€â”€ datasets.py           # Dataset loaders
â”œâ”€â”€ model.py              # Model loading and generation
â”œâ”€â”€ difficulty.py         # Difficulty estimation
â”œâ”€â”€ energy.py             # Energy measurement
â”œâ”€â”€ ars.py                # ARS core implementation
â”œâ”€â”€ evaluation.py         # Evaluation and metrics
â”œâ”€â”€ benchmark.py          # Benchmarking harness
â””â”€â”€ testing.py            # Test mode
```

## Policies

### Vanilla
Standard step-by-step reasoning without constraints.

### TALE (Token-Aware Limited Explanation)
Constrains reasoning to a fixed token budget.

### CGRS (Confidence-Guided Reflection Scheduling)
Reflects only when uncertain, minimizing unnecessary computation.

### ARS (Adaptive Reflection Scheduling)
Dynamically selects reasoning depth based on difficulty:
- **FAST mode**: Chain-of-Draft for simple questions
- **MOD mode**: Elastic reasoning with token budget
- **DEEP mode**: Deep reflection with verification

## Configuration

Key parameters can be configured via command-line arguments:

- `--max_new_tokens`: Maximum tokens to generate (default: 1024)
- `--d1`, `--d2`: Difficulty thresholds for mode selection
- `--temperature`: Sampling temperature (default: 0.6)
- `--top_p`: Top-p sampling parameter (default: 0.95)

See `python -m ars.main --help` for full options.

## Supported Models

- Qwen2.5-Math-1.5B-Instruct
- Qwen2.5-Math-7B-Instruct
- DeepSeek-R1-Distill-Qwen-7B

## Supported Datasets

- **MATH500**: Challenging math problems
- **GSM8K**: Grade school math word problems
- **ARC**: AI2 Reasoning Challenge

## Results

Results are saved in the specified output directory:

```
results/
â”œâ”€â”€ benchmark/
â”‚   â”œâ”€â”€ benchmark_summary.csv
â”‚   â”œâ”€â”€ benchmark_summary.json
â”‚   â””â”€â”€ <model>__<dataset>__<policy>/
â”‚       â”œâ”€â”€ samples.jsonl
â”‚       â”œâ”€â”€ summary.json
â”‚       â””â”€â”€ debug_sample_*.txt
â””â”€â”€ single/
    â”œâ”€â”€ samples.jsonl
    â””â”€â”€ summary.json
```

## Metrics

- **Accuracy**: Percentage of correct answers
- **TPC (Tokens Per Correct)**: Average tokens used per correct answer
- **Latency**: Mean and P95 inference time
- **Energy**: Joules per correct answer

## Citation

If you use this code in your research, please cite:

```bibtex
@software{ars2025,
  title={ARS: Adaptive Reflection Scheduling for Efficient LLM Reasoning},
  author={Your Name},
  year={2025},
  url={https://github.com/yourusername/ars}
}
```

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## Acknowledgments

- Built with ðŸ¤— Transformers
- Datasets from HuggingFace Hub
- Inspired by recent work in efficient LLM inference
